{
    "lr": 0.001,
    "batch_size": 1024,
    "epochs": 200,
    "feature_dim": 16,
    "hidden_units": [
        512,
        256,
        128
    ],
    "dropout": 0.2,
    "cross_layers": 2,
    "low_rank": 32,
    "attention_layers": 3,
    "num_heads": 2
}